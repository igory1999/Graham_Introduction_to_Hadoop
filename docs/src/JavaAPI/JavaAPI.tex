\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage{default}

\mode<presentation>
%{ \usetheme{boxes} }


\usetheme{Madrid}

\usepackage{times}
\usepackage{graphicx}
\usepackage{tabulary}
\usepackage{listings}
\usepackage{verbatimbox}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage[absolute,overlay]{textpos}
\usepackage{pgfpages}
\usepackage{color}

\pgfdeclareimage[height=1.0cm]{logo_rcc}{../icons/logo_rcc.png}
\setlength{\TPHorizModule}{1mm}
\setlength{\TPVertModule}{1mm}
\newcommand{\RCCLogo}{
\begin{textblock}{14}(1.5,1.5)
  \pgfuseimage{logo_rcc}
\end{textblock}
}

\definecolor{mycolorcli}{RGB}{53,154,26}
\definecolor{mycolorcode}{RGB}{0,0,255}
\definecolor{mycolordef}{RGB}{255,0,0}
\definecolor{mycolorlink}{RGB}{184,4,255}

\title{\huge{Java API to MapReduce}}
\author{Igor Yakushin \\ \texttt{ivy2@uchicago.edu}}
%\date{January 20, 2018}

\definecolor{ChicagoMaroon}{RGB}{128,0,0}

\setbeamercolor{title}{bg=ChicagoMaroon}

\begin{document}

\setbeamertemplate{navigation symbols}{}

\setbeamercolor{fcolor}{fg=white,bg=ChicagoMaroon}
\setbeamertemplate{footline}{
\begin{beamercolorbox}[ht=4ex,leftskip=1.4cm,rightskip=.3cm]{fcolor}
\hrule
\vspace{0.1cm}
   \hfill \insertshortdate \hfill \insertframenumber/\inserttotalframenumber
\end{beamercolorbox}
}

\setbeamercolor{frametitle}{bg=ChicagoMaroon,fg=white}

\begin{frame}
\titlepage
\end{frame}




\subsection{Java API}
\begin{frame}[fragile]
 \frametitle{MapReduce: using Java API}

\begin{itemize}
\item Import various Hadoop related modules:
\end{itemize}
{\color{mycolorcode}
  \begin{lstlisting}[frame=single, basicstyle=\tiny,language=java]
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
  \end{lstlisting}
}
\end{frame}


\begin{frame}[fragile]
 \frametitle{MapReduce: using Java API}

\begin{itemize}
  \item Inside your own {\color{mycolorcode}WordCount} class, create a class that extends {\color{mycolorcode}Mapper}:
\end{itemize}
{\color{mycolorcode}
  \begin{lstlisting}[frame=single, basicstyle=\tiny,language=java]
public class WordCount {

  public static class TokenizerMapper
      extends Mapper<Object, Text, Text, IntWritable>{

      private final static IntWritable one = new IntWritable(1);
      private Text word = new Text();

      public void map(Object key, Text value, Context context
                      ) throws IOException, InterruptedException {
          StringTokenizer itr = new StringTokenizer(value.toString());
          while (itr.hasMoreTokens()) {
              word.set(itr.nextToken());
              context.write(word, one);
          }
      }
  }
}
  \end{lstlisting}
}
\begin{itemize}
  \item {\color{mycolorcode}TokenizerMapper} overwrites {\color{mycolorcode}map} method to split each line into words and return {\color{mycolorcode}$(word, 1)$} for each {\color{mycolorcode}$word$}.
\end{itemize}

\end{frame}


\begin{frame}[fragile]
 \frametitle{MapReduce: using Java API}
\begin{itemize}
  \item {\color{mycolorcode}IntSumReducer} extends {\color{mycolorcode}Reducer} class and overwrites its {\color{mycolorcode}reduce} method to count number of words:
\end{itemize}
{\color{mycolorcode}
  \begin{lstlisting}[frame=single, basicstyle=\tiny,language=java]
  public static class IntSumReducer
      extends Reducer<Text,IntWritable,Text,IntWritable> {
      private IntWritable result = new IntWritable();

      public void reduce(Text key, Iterable<IntWritable> values,
                       Context context
                         ) throws IOException, InterruptedException {
          int sum = 0;
          for (IntWritable val : values) {
              sum += val.get();
          }
          result.set(sum);
          context.write(key, result);
      }
  }
  \end{lstlisting}
}
\end{frame}


\begin{frame}[fragile]
 \frametitle{MapReduce: using Java API}

\begin{itemize}
  \item {\color{blue}main} function sets up configuration, launches MapReduce job and writes the results to a file:
\end{itemize}
{\color{mycolorcode}
  \begin{lstlisting}[frame=single, basicstyle=\tiny,language=java]
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
  \end{lstlisting}
}
\end{frame}

\begin{frame}[fragile]
 \frametitle{MapReduce: using Java API}
{\color{mycolorcli}
  \begin{lstlisting}[frame=single, basicstyle=\tiny]
source env.sh
mkdir wordcount_classes
javac -cp /opt/cloudera/parcels/CDH/lib/hadoop/*:\
          /opt/cloudera/parcels/CDH/lib/hadoop/client-0.20/*\ 
          -d wordcount_classes WordCount.java
jar -cvf wordcount.jar -C wordcount_classes/ .

hdfs dfs -mkdir /user/$USER/wordcount
hdfs dfs -rm -r -f /user/$USER/wordcount/output
hdfs dfs -put  /software/matlab-2014b-x86_64/\
               toolbox/distcomp/examples/integration/old/pbs/README 
               /user/$USER/wordcount/

hadoop jar wordcount.jar WordCount 
           /user/$USER/wordcount/README /user/$USER/wordcount/output

hdfs dfs -ls /user/ivy2/wordcount/output
hdfs dfs -cat wordcount/output/part-r-00000
hdfs dfs -cat wordcount/output/part-r-000* | sort > out.txt
hdfs dfs -getmerge wordcount/output merged.txt
cat merged.txt | grep sort
\end{lstlisting}
}


\end{frame}


\end{document}
